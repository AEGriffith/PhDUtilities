{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XYp6UKUHrinH",
        "9tR5ojGwrkB7",
        "lIJR6LMeRlH9"
      ],
      "mount_file_id": "1k3p9vzcZ6ANdSkJijBKQcWFgmwTLg4Mz",
      "authorship_tag": "ABX9TyO/+nlBEFkoKcvw9SjzcChM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AEGriffith/PhDUtilities/blob/main/ACM_Paper_Exctractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ACM Search Information\n",
        "#@markdown Enter your search url:\n",
        "search_url = \"https://dl.acm.org/action/doSearch?fillQuickSearch=false&target=advanced&ContentItemType=research-article&expand=dl&CCSAnd=60&AfterYear=2018&BeforeYear=2023&AllField=%28Keyword%3A%28Creativity%29+OR+%28Fulltext%3A%28AI%2C+agent%2C+%22Artificial+Intelligence%22%29+AND+Fulltext%3A%28Creativity%29+AND+Fulltext%3A%28Collab*+Support+Tool%29%29%29\" #@param {type: \"string\"}\n",
        "#@markdown Enter the first and last search year:\n",
        "start_year = 2018 #@param {type: \"integer\"}\n",
        "end_year = 2023 #@param {type: \"integer\"}\n",
        "#@markdown Enter the filepath to save csv file (including csv name)\n",
        "filepath = \"/content/drive/MyDrive/Quals/papers.csv\" #@param {type: \"string\"} \n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KD5DuZ6ip7_4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: This code is based on a script that my colleague, Gloria Katuka (https://github.com/gkatuka), wrote. I have adapted it for this specific use case."
      ],
      "metadata": {
        "id": "Y18jGNbM7YlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: Selenium & Colab Compatibility Issue Fix: \n",
        "\n",
        "\"After the runtime status says connected, open the command palette (ctrl + shift + p) and select \"Use Fallback Runtime Version\"\n",
        "\n",
        "[see full answer on stackoverflow\n",
        "](https://stackoverflow.com/questions/75155063/selenium-use-chrome-on-colab-got-unexpectedly-exited/75156515)"
      ],
      "metadata": {
        "id": "gatRpdZ87WL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run All"
      ],
      "metadata": {
        "id": "WBgn7corQRo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "XYp6UKUHrinH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# install chromium, its driver, and selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install -U selenium\n",
        "\n",
        "# set options to be headless, ..\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "metadata": {
        "id": "hCA7fJRXHhKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "35mJc4vLoWvK"
      },
      "outputs": [],
      "source": [
        "import urllib3\n",
        "import pandas as pd\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.webdriver.support.wait import WebDriverWait\n",
        "from collections import Counter\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "9tR5ojGwrkB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_link(url, year):\n",
        "  \"\"\"\n",
        "    This function modifies a given URL by setting the page size to 50, setting the date range to search\n",
        "    within a given year, and finding the number of pages required to display all search results.\n",
        "\n",
        "    Parameters:\n",
        "    url (str): The URL to be modified.\n",
        "    year (int): The year to set the date range to.\n",
        "\n",
        "    Returns:\n",
        "    Tuple[str, int]: A tuple containing the modified URL, and the number of pages required to display all search results.\n",
        "  \"\"\"\n",
        "\n",
        "  # Set the page size to 50 by replacing any existing pageSize parameter in the URL, or by adding one if it doesn't exist.\n",
        "  if re.findall(r'pageSize=\\d+', url):\n",
        "    url = re.sub(r'pageSize=\\d+', 'pageSize=50', url)\n",
        "  else: \n",
        "    url = url + \"&pageSize=50\"\n",
        "  # Set the date range to search within a given year.\n",
        "  # This is done so that we can search one year at a time, as the ACM limits the number of papers shown to 2000.\n",
        "  url = re.sub(r'AfterYear=\\d+', 'AfterYear={year}', url)\n",
        "  url = re.sub(r'BeforeYear=\\d+', 'BeforeYear={year}', url)\n",
        "  # Find the number of pages by dividing the number of search results by 50 (rounded up).\n",
        "  # To do this the function uses Selenium to get the html source of the page, and then uses BeautifulSoup to parse it.\n",
        "  driver.get(url.format(year=year))\n",
        "  WebDriverWait(driver, 10)\n",
        "  html = driver.page_source\n",
        "  soup = BeautifulSoup(html, \"html.parser\")\n",
        "  num_results = int((soup.find(\"span\", {\"class\": \"hitsLength\"}).text).replace(\",\",\"\"))\n",
        "  num_pages: int = (num_results // 50) + 1\n",
        "  # Replace the 'startPage' parameter with the current page number or by adding one if it doesn't exist.\n",
        "  # This will allow the function to navigate through multiple pages of results.\n",
        "  if re.findall(r'startPage=\\d+', url):\n",
        "    url = re.sub(r'startPage=\\d+', 'startPage={page}', url)\n",
        "  else:\n",
        "    url = url + \"&startPage={page}\"\n",
        "  return url, num_pages"
      ],
      "metadata": {
        "id": "Anyh7m8ArmWi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paper_info(search_url, filepath):\n",
        "  \"\"\"\n",
        "    This function extracts information about papers that match a given search query on the ACM Digital Library. \n",
        "    It returns a DataFrame containing the title, DOI, month, year, citation count, and download count for each paper,\n",
        "    and saves it as a csv.\n",
        "\n",
        "    Parameters:\n",
        "    search_url (str): The search URL for the query on the ACM Digital Library\n",
        "\n",
        "    Returns:\n",
        "    df (DataFrame): A DataFrame containing the extracted information for each paper.\n",
        "    \"\"\"\n",
        "\n",
        "  paper_dict = {\"paper_doi\": [], \"paper_title\": [], \"paper_month\": [], \"paper_year\":[], \"citation_count\": [], \"download_count\": []}\n",
        "  paper_urls = []\n",
        "\n",
        "  # Loop through all years in the specified date range\n",
        "  for year in range(start_year, end_year+1):\n",
        "    \n",
        "    page_url, num_pages = modify_link(search_url, year)\n",
        "\n",
        "    # loop through all the pages of the search results for each year\n",
        "    for page in range(num_pages):\n",
        "      driver.get(page_url.format(page=page, year=year))\n",
        "      WebDriverWait(driver, 10)\n",
        "      html = driver.page_source\n",
        "      soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "      # Extract title and doi\n",
        "      title_spans = soup.find_all(\"span\", {\"class\": \"hlFld-Title\"})\n",
        "      for title_span in title_spans:\n",
        "        paper_url = title_span.find(\"a\", href=True)\n",
        "        if paper_url:\n",
        "          paper_url = urllib3.util.url.parse_url(paper_url[\"href\"]).url\n",
        "          paper_urls.append(f'https://dlc.acm.org/{paper_url}')\n",
        "        paper_title = title_span.find(\"a\").text\n",
        "        paper_dict[\"paper_title\"].append(paper_title)\n",
        "        paper_dict[\"paper_doi\"].append(paper_url)\n",
        "\n",
        "      # Extract citation and download counts\n",
        "      metrics = soup.find_all(\"li\", {\"class\": \"metric-holder\"})\n",
        "      for metric in metrics:\n",
        "        # citation count\n",
        "        paper_citation = metric.find(\"div\", {\"class\": \"citation\"})\n",
        "        if paper_citation:\n",
        "          citation = paper_citation.text\n",
        "          citation = citation.replace(\"Total Citations\", \"\")\n",
        "          citation = citation.replace(\",\", \"\")\n",
        "          citation = citation.replace(\" \", \"\")\n",
        "          paper_dict[\"citation_count\"].append(int(citation))\n",
        "        else:\n",
        "          paper_dict[\"citation_count\"].append(0)\n",
        "        # download count\n",
        "        paper_download = metric.find(\"div\", {\"class\": \"metric\"})\n",
        "        if paper_download:\n",
        "          download = paper_download.text\n",
        "          download = download.replace(\"Total Downloads\", \"\")\n",
        "          download = download.replace(\",\", \"\")\n",
        "          download = download.replace(\" \", \"\")\n",
        "          paper_dict[\"download_count\"].append(int(download))\n",
        "        else:\n",
        "          paper_dict[\"download_count\"].append(0)\n",
        "\n",
        "      # Extract paper dates\n",
        "      paper_dates = soup.find_all(\"div\", {\"class\": \"bookPubDate\"})\n",
        "      for date in paper_dates:\n",
        "        date = date.text\n",
        "        # get month, year from date\n",
        "        month, year = date.split(\" \")\n",
        "        paper_dict[\"paper_month\"].append(month)\n",
        "        paper_dict[\"paper_year\"].append(year)\n",
        "  df = pd.DataFrame(paper_dict)\n",
        "  df.to_csv(filepath)\n",
        "  driver.quit()\n",
        "  return df"
      ],
      "metadata": {
        "id": "XEL8O8LDHIC7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute Search"
      ],
      "metadata": {
        "id": "irv9oafC-oT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "# Get paper lists and information and put it into a dataframe and save as csv.\n",
        "df = get_paper_info(search_url, filepath)\n"
      ],
      "metadata": {
        "id": "FhIOTPlZMnky"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specific processing for my Qualifying Exam"
      ],
      "metadata": {
        "id": "lIJR6LMeRlH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"download_cutoff\"] = False\n",
        "df[\"citation_cutoff\"] = False\n",
        "\n",
        "for year in range(start_year, end_year+1):\n",
        "  df_by_year = df[df['paper_year'].astype(int) == year]\n",
        "  avg_downloads = df_by_year.loc[:, 'download_count'].mean()\n",
        "  df_keep_download = df_by_year[(df_by_year['download_count'] >= avg_downloads)]\n",
        "  avg_citations = df_by_year.loc[:, 'citation_count'].mean()\n",
        "  df_keep_citation = df_by_year[(df_by_year['citation_count'] >= avg_citations)]\n",
        "  df_lose = df_by_year[(df_by_year['download_count'] < avg_downloads)]\n",
        "  df.loc[df_keep_download.index, 'download_cutoff'] = True\n",
        "  df.loc[df_keep_citation.index, 'citation_cutoff'] = True\n",
        "\n",
        "df.to_csv(filepath)"
      ],
      "metadata": {
        "id": "n6lbG9xb3F5h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count number of papers that meet the criteria for downloads or citations\n",
        "print(\"Number of papers that meet the criteria for downloads: \", df[df['download_cutoff'] == True].shape[0])\n",
        "print(\"Number of papers that meet the criteria for citations: \", df[df['citation_cutoff'] == True].shape[0])\n",
        "\n",
        "# count the number of papers that meet the criteria for downloads but not citations\n",
        "print(\"Number of papers that meet the criteria for downloads but not citations: \", df[(df['download_cutoff'] == True) & (df['citation_cutoff'] == False)].shape[0])\n",
        "\n",
        "# count the number of papers that meet the criteria for citations but not downloads\n",
        "print(\"Number of papers that meet the criteria for citations but not downloads: \", df[(df['download_cutoff'] == False) & (df['citation_cutoff'] == True)].shape[0])\n",
        "\n",
        "# count the number of papers that meet the criteria for both downloads and citations\n",
        "print(\"Number of papers that meet the criteria for both downloads and citations: \", df[(df['download_cutoff'] == True) & (df['citation_cutoff'] == True)].shape[0])\n",
        "\n",
        "# count the number of papers that meet the criteria for either downloads or citations or both\n",
        "print(\"Number of papers that meet the criteria for both downloads and citations: \", df[(df['download_cutoff'] == True) | (df['citation_cutoff'] == True)].shape[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSwVuNJdmpeY",
        "outputId": "8dbbf4d5-af7c-48dc-93ab-d6997ccc3972"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of papers that meet the criteria for downloads:  845\n",
            "Number of papers that meet the criteria for citations:  923\n",
            "Number of papers that meet the criteria for downloads but not citations:  298\n",
            "Number of papers that meet the criteria for citations but not downloads:  376\n",
            "Number of papers that meet the criteria for both downloads and citations:  547\n",
            "Number of papers that meet the criteria for both downloads and citations:  1221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of papers that meet the criteria for both downloads and citations for each year\n",
        "for year in range(start_year, end_year + 1):\n",
        "  print(f\"Total number of papers in {year}: \", df[df['paper_year'].astype(int) == year].shape[0])\n",
        "  print(f\"Number of papers that meet the criteria for both downloads and citations in {year}: \", df[(df['download_cutoff'] == True) & (df['citation_cutoff'] == True) & (df['paper_year'].astype(int) == year)].shape[0])\n",
        "  print(f\"Number of papers that meet the criteria for downloads but not citations in {year}: \", df[(df['download_cutoff'] == True) & (df['citation_cutoff'] == False) & (df['paper_year'].astype(int) == year)].shape[0])\n",
        "  print(f\"Number of papers that meet the criteria for citations but not downloads in {year}: \", df[(df['download_cutoff'] == False) & (df['citation_cutoff'] == True) & (df['paper_year'].astype(int) == year)].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrhHPa9Enq--",
        "outputId": "3f17b833-c675-47c5-a9c8-8cc23742a84a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of papers in 2018:  432\n",
            "Number of papers that meet the criteria for both downloads and citations in 2018:  96\n",
            "Number of papers that meet the criteria for downloads but not citations in 2018:  26\n",
            "Number of papers that meet the criteria for citations but not downloads in 2018:  54\n",
            "Total number of papers in 2019:  449\n",
            "Number of papers that meet the criteria for both downloads and citations in 2019:  88\n",
            "Number of papers that meet the criteria for downloads but not citations in 2019:  38\n",
            "Number of papers that meet the criteria for citations but not downloads in 2019:  53\n",
            "Total number of papers in 2020:  508\n",
            "Number of papers that meet the criteria for both downloads and citations in 2020:  95\n",
            "Number of papers that meet the criteria for downloads but not citations in 2020:  39\n",
            "Number of papers that meet the criteria for citations but not downloads in 2020:  62\n",
            "Total number of papers in 2021:  624\n",
            "Number of papers that meet the criteria for both downloads and citations in 2021:  132\n",
            "Number of papers that meet the criteria for downloads but not citations in 2021:  72\n",
            "Number of papers that meet the criteria for citations but not downloads in 2021:  105\n",
            "Total number of papers in 2022:  874\n",
            "Number of papers that meet the criteria for both downloads and citations in 2022:  135\n",
            "Number of papers that meet the criteria for downloads but not citations in 2022:  123\n",
            "Number of papers that meet the criteria for citations but not downloads in 2022:  88\n",
            "Total number of papers in 2023:  15\n",
            "Number of papers that meet the criteria for both downloads and citations in 2023:  1\n",
            "Number of papers that meet the criteria for downloads but not citations in 2023:  0\n",
            "Number of papers that meet the criteria for citations but not downloads in 2023:  14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of papers that meet the criteria for either downloads or citations or both: \", df[\n",
        "    (df['download_cutoff'] == True) | (df['citation_cutoff'] == True)].shape[0])\n",
        "\n",
        "# count the number of papers that meet the criteria for either downloads or citations or both for each year\n",
        "for year in range(start_year, end_year + 1):\n",
        "    print(\"Number of papers that meet the criteria for either downloads or citations or both in {}: \".format(year), df[\n",
        "        ((df['download_cutoff'] == True) | (df['citation_cutoff'] == True)) & (\n",
        "                    df['paper_year'].astype(int) == year)].shape[0])\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVVQyxj6pNCH",
        "outputId": "5e7909fd-5fd9-447c-b81c-a505a5c2f972"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of papers that meet the criteria for either downloads or citations or both:  1221\n",
            "Number of papers that meet the criteria for either downloads or citations or both in 2018:  176\n",
            "Number of papers that meet the criteria for either downloads or citations or both in 2019:  179\n",
            "Number of papers that meet the criteria for either downloads or citations or both in 2020:  196\n",
            "Number of papers that meet the criteria for either downloads or citations or both in 2021:  309\n",
            "Number of papers that meet the criteria for either downloads or citations or both in 2022:  346\n",
            "Number of papers that meet the criteria for either downloads or citations or both in 2023:  15\n"
          ]
        }
      ]
    }
  ]
}